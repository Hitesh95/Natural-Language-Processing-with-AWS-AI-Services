{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a social media text analytics solution\n",
    "\n",
    "\n",
    "\n",
    "### Steps\n",
    "1. Download review dataset from [Yelp Reviews NLP Fast.ai](https://registry.opendata.aws/fast-ai-nlp/).\n",
    "2. Register raw data set as a table with the [AWS Glue Data Catalog](https://docs.aws.amazon.com/glue/latest/dg/tables-described.html).\n",
    "3. Run a pyspark [AWS Glue Job] to convert data set into [Parquet](https://parquet.apache.org/) and get review sentiment with [Amazon Comprehend](https://aws.amazon.com/comprehend/).\n",
    "4. Store transformed results in a new curated data set.\n",
    "5. Serverless query the optimzied data set with [Amazon Athena](https://aws.amazon.com/athena/)\n",
    "6. Provide visual insights of the results with [Amazon QuickSight](https://aws.amazon.com/quicksight/) or [Bokeh](https://bokeh.pydata.org/en/latest/)\n",
    "\n",
    "This notebook is inspired by the blog [How to scale sentiment analysis using Amazon Comprehend, AWS Glue and Amazon Athena\n",
    "](https://aws.amazon.com/blogs/machine-learning/how-to-scale-sentiment-analysis-using-amazon-comprehend-aws-glue-and-amazon-athena/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding out the current execution role of the Notebook\n",
    "We are using SageMaker Python SDK to retrieve the current role for this Notebook which needs to be enhanced to support the functionality in AWS Glue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComprehendEventsBlog-SageMakerRole-1PKY0AT53UQJ4\n"
     ]
    }
   ],
   "source": [
    "# Import SageMaker Python SDK to get the Session and execution_role\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "role_name = role[role.rfind('/') + 1:]\n",
    "print(role_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding AWS Glue as an additional trusted entity to this role\n",
    "This step is needed if you want to pass the execution role of this Notebook while calling Glue APIs as well without creating an additional **Role**. If you have not used AWS Glue before, then this step is mandatory. \n",
    "\n",
    "If you have used AWS Glue previously, then you should have an already existing role that can be used to invoke Glue APIs. In that case, you can pass that role while calling Glue (later in this notebook) and skip this next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the IAM dashboard, please click on **Roles** on the left sidenav and search for this Role. Once the Role appears, click on the Role to go to its **Summary** page. Click on the **Trust relationships** tab on the **Summary** page to add AWS Glue as an additional trusted entity. \n",
    "\n",
    "Click on **Edit trust relationship** and replace the JSON with this JSON.\n",
    "```\n",
    "{\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": {\n",
    "        \"Service\": [\n",
    "          \"sagemaker.amazonaws.com\",\n",
    "          \"glue.amazonaws.com\"\n",
    "        ]\n",
    "      },\n",
    "      \"Action\": \"sts:AssumeRole\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "Once this is complete, click on **Update Trust Policy** and you are done.\n",
    "\n",
    "![IAM Roles](../../docs/assets/images/iam_roles_hl.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://console.aws.amazon.com/iam/home?region=us-east-1#/roles/ComprehendEventsBlog-SageMakerRole-1PKY0AT53UQJ4\n"
     ]
    }
   ],
   "source": [
    "print(\"https://console.aws.amazon.com/iam/home?region={0}#/roles/{1}\".format(region, role_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and setup step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "import project_path\n",
    "from lib import workshop\n",
    "\n",
    "glue = boto3.client('glue')\n",
    "s3 = boto3.resource('s3')\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "database_name = 'yelp' # AWS Glue Data Catalog Database Name\n",
    "raw_table_name = 'raw_reviews' # AWS Glue Data Catalog raw table name\n",
    "parquet_table_name = 'parq_reviews' # AWS Glue Data Catalog parquet table name\n",
    "open_data_bucket = 'fast-ai-nlp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Download Yelp Reviews](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-example-download-file.html) \n",
    "\n",
    "We will download the reviews from the Fast.ai NLP dataset available on the [AWS Open Data Registry](https://registry.opendata.aws/fast-ai-nlp/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    s3.Bucket(open_data_bucket).download_file('yelp_review_full_csv.tgz', 'yelp_review_full_csv.tgz')\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == \"404\":\n",
    "        print(\"The object does not exist.\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Untar Yelp Reviews\n",
    "\n",
    "There are two `csv` files in the tarball. One is called `train.csv`, the other is `test.csv`. If we were to leverage this data set to build an new AI/ML model we would have cleaned and split data sets for both train and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp_review_full_csv/\n",
      "yelp_review_full_csv/train.csv\n",
      "yelp_review_full_csv/readme.txt\n",
      "yelp_review_full_csv/test.csv\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf yelp_review_full_csv.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those interested, The `readme.txt` file describes in more details the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yelp Review Full Star Dataset\r\n",
      "\r\n",
      "Version 1, Updated 09/09/2015\r\n",
      "\r\n",
      "ORIGIN\r\n",
      "\r\n",
      "The Yelp reviews dataset consists of reviews from Yelp. It is extracted from the Yelp Dataset Challenge 2015 data. For more information, please refer to http://www.yelp.com/dataset_challenge\r\n",
      "\r\n",
      "The Yelp reviews full star dataset is constructed by Xiang Zhang (xiang.zhang@nyu.edu) from the above dataset. It is first used as a text classification benchmark in the following paper: Xiang Zhang, Junbo Zhao, Yann LeCun. Character-level Convolutional Networks for Text Classification. Advances in Neural Information Processing Systems 28 (NIPS 2015).\r\n",
      "\r\n",
      "\r\n",
      "DESCRIPTION\r\n",
      "\r\n",
      "The Yelp reviews full star dataset is constructed by randomly taking 130,000 training samples and 10,000 testing samples for each review star from 1 to 5. In total there are 650,000 trainig samples and 50,000 testing samples.\r\n",
      "\r\n",
      "The files train.csv and test.csv contain all the training samples as comma-sparated values. There are 2 columns in them, corresponding to class index (1 to 5) and review text. The review texts are escaped using double quotes (\"), and any internal double quote is escaped by 2 double quotes (\"\"). New lines are escaped by a backslash followed with an \"n\" character, that is \"\\n\".\r\n"
     ]
    }
   ],
   "source": [
    "!cat yelp_review_full_csv/readme.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View raw csv file\n",
    "\n",
    "We will use [Pandas](https://pandas.pydata.org/) to read the csv and view the data set. You will notice the data contains 2 unnamed columns for rating and review. The rating is between 1-5 and the review is a free form text field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Got a letter in the mail last week that said Dr. Goldberg is moving to Arizona to take a new position there in June.  He will be missed very much.  \\n\\nI think finding a new doctor in NYC that you actually like might almost be as awful as trying to find a date!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before  moving to Arizona, but let me tell you, STAY AWAY from this doctor and this office. I was going to Dr. Johnson before he left and Goldberg took over when Johnson left. He is not a caring doctor. He is only interested in the co-pay and having you come in for medication refills every month. He will not give refills and could less about patients's financial situations. Trying to get your 90 days mail away pharmacy prescriptions through this guy is a joke. And to make matters even worse, his office staff is incompetent. 90% of the time when you call the office, they'll put you through to a voice mail, that NO ONE ever answers or returns your call. Both my adult children and husband have decided to leave this practice after experiencing such frustration. The entire office has an attitude like they are doing you a favor. Give me a break! Stay away from this doc and the practice. You deserve better and they will not be there when you really need them. I have never felt compelled to write a bad review about anyone until I met this pathetic excuse for a doctor who is all about the money.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  \\\n",
       "0  5   \n",
       "1  2   \n",
       "2  4   \n",
       "3  4   \n",
       "4  1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1  \n",
       "0  dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "1  Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "2  Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "3  Got a letter in the mail last week that said Dr. Goldberg is moving to Arizona to take a new position there in June.  He will be missed very much.  \\n\\nI think finding a new doctor in NYC that you actually like might almost be as awful as trying to find a date!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "4  I don't know what Dr. Goldberg was like before  moving to Arizona, but let me tell you, STAY AWAY from this doctor and this office. I was going to Dr. Johnson before he left and Goldberg took over when Johnson left. He is not a caring doctor. He is only interested in the co-pay and having you come in for medication refills every month. He will not give refills and could less about patients's financial situations. Trying to get your 90 days mail away pharmacy prescriptions through this guy is a joke. And to make matters even worse, his office staff is incompetent. 90% of the time when you call the office, they'll put you through to a voice mail, that NO ONE ever answers or returns your call. Both my adult children and husband have decided to leave this practice after experiencing such frustration. The entire office has an attitude like they are doing you a favor. Give me a break! Stay away from this doc and the practice. You deserve better and they will not be there when you really need them. I have never felt compelled to write a bad review about anyone until I met this pathetic excuse for a doctor who is all about the money.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "df = pd.read_csv('yelp_review_full_csv/train.csv', header=None)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Create S3 Bucket](https://docs.aws.amazon.com/AmazonS3/latest/gsg/CreatingABucket.html)\n",
    "\n",
    "We will create an S3 bucket that will be used throughout the workshop for storing our data.\n",
    "\n",
    "[s3.create_bucket](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.create_bucket) boto3 documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalake-e37e8e2a-ffde-4a1f-b7c3-959a76f0128f\n"
     ]
    }
   ],
   "source": [
    "bucket = workshop.create_bucket(region, session, 'datalake-')\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Upload to S3](https://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html)\n",
    "\n",
    "Next, we will upload the json file created above to S3 to be used later.\n",
    "\n",
    "[s3.upload_file](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.upload_file) boto3 documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'train.csv'\n",
    "session.resource('s3').Bucket(bucket).Object(os.path.join('yelp', 'raw', file_name)).upload_file('yelp_review_full_csv/'+file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the [AWS Glue Catalog Database](https://docs.aws.amazon.com/glue/latest/dg/define-database.html)\n",
    "\n",
    "When you define a table in the AWS Glue Data Catalog, you add it to a database. A database is used to organize tables in AWS Glue. You can organize your tables using a crawler or using the AWS Glue console. A table can be in only one database at a time.\n",
    "\n",
    "There is a central Glue Catalog for each AWS account. When creating the database you will use your account id declared above as `account_id`\n",
    "\n",
    "[glue.create_database](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/glue.html#Glue.Client.create_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "workshop.create_db(glue, account_id, database_name, 'Database for Yelp Reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Create the Raw table in Glue](https://docs.aws.amazon.com/glue/latest/dg/tables-described.html)\n",
    "\n",
    "When you define a table in AWS Glue, you also specify the value of a classification field that indicates the type and format of the data that's stored in that table. If a crawler creates the table, these classifications are determined by either a built-in classifier or a custom classifier. If you create a table manually in the console or by using an API, you specify the classification when you define the table. For more information about creating a table using the AWS Glue console, see [Working with Tables on the AWS Glue Console](https://docs.aws.amazon.com/glue/latest/dg/console-tables.html).\n",
    "\n",
    "[glue.create_table](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/glue.html#Glue.Client.create_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AlreadyExistsException",
     "evalue": "An error occurred (AlreadyExistsException) when calling the CreateTable operation: Table already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAlreadyExistsException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2762be5fce19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;34m'TableType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'EXTERNAL_TABLE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         'Parameters': {\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;34m'classification'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         }\n\u001b[1;32m     38\u001b[0m     }\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAlreadyExistsException\u001b[0m: An error occurred (AlreadyExistsException) when calling the CreateTable operation: Table already exists."
     ]
    }
   ],
   "source": [
    "location = 's3://{0}/yelp/raw'.format(bucket)\n",
    "\n",
    "response = glue.create_table(\n",
    "    CatalogId=account_id,\n",
    "    DatabaseName=database_name,\n",
    "    TableInput={\n",
    "        'Name': raw_table_name,\n",
    "        'Description': 'Raw Yelp reviews dataset',\n",
    "        'StorageDescriptor': {\n",
    "            'Columns': [\n",
    "                {\n",
    "                    'Name': 'rating',\n",
    "                    'Type': 'tinyint',\n",
    "                    'Comment': 'Rating of from the Yelp review'\n",
    "                },\n",
    "                {\n",
    "                    'Name': 'review',\n",
    "                    'Type': 'string',\n",
    "                    'Comment': 'Review text of from the Yelp review'\n",
    "                }\n",
    "            ],\n",
    "            'Location': location,\n",
    "            'InputFormat': 'org.apache.hadoop.mapred.TextInputFormat',\n",
    "            'OutputFormat': 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',\n",
    "            'SerdeInfo': {\n",
    "                'SerializationLibrary': 'org.apache.hadoop.hive.serde2.OpenCSVSerde',\n",
    "                'Parameters': {\n",
    "                    'escapeChar': '\\\\',\n",
    "                    'separatorChar': ',',\n",
    "                    'serialization.format': '1'\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        'TableType': 'EXTERNAL_TABLE',\n",
    "        'Parameters': {\n",
    "            'classification': 'csv'\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Yelp Raw Reviews Data \n",
    "\n",
    "To see the raw Yelp reviews we will be installing a python library for querying the data in the Glue Data Catalog with Athena. More information about [PyAthena](https://pypi.org/project/PyAthena/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyAthena\n",
      "  Downloading PyAthena-2.2.0-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: botocore>=1.5.52 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from PyAthena) (1.20.61)\n",
      "Collecting tenacity>=4.1.0\n",
      "  Downloading tenacity-7.0.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: boto3>=1.4.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from PyAthena) (1.17.61)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.4.4->PyAthena) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.4.4->PyAthena) (0.4.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.5.52->PyAthena) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.5.52->PyAthena) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.5.52->PyAthena) (1.15.0)\n",
      "Installing collected packages: tenacity, PyAthena\n",
      "Successfully installed PyAthena-2.2.0 tenacity-7.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install PyAthena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>I love that NY NY's food court isn't set up li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>I had the brisket &amp; pastrami. most ny type del...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>best meat to bread ratio i've experienced.    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>OMG!  Greenberg's serves up some of the most d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>The System: nn1 Star: Almost impossible to get...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             review\n",
       "0       4  I love that NY NY's food court isn't set up li...\n",
       "1       3  I had the brisket & pastrami. most ny type del...\n",
       "2       4  best meat to bread ratio i've experienced.    ...\n",
       "3       5  OMG!  Greenberg's serves up some of the most d...\n",
       "4       3  The System: nn1 Star: Almost impossible to get..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyathena import connect\n",
    "from pyathena.pandas.util import as_pandas\n",
    "\n",
    "cursor = connect(region_name=region, s3_staging_dir='s3://'+bucket+'/yelp/temp').cursor()\n",
    "cursor.execute('select * from ' + database_name + '.' + raw_table_name + ' limit 10')\n",
    "\n",
    "df = as_pandas(cursor)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Raw data to provide insights and visualization\n",
    "\n",
    "### [Detect Sentiment](https://docs.aws.amazon.com/comprehend/latest/dg/how-sentiment.html)\n",
    "We are now going to transform the raw data using [PySpark](http://spark.apache.org/docs/latest/api/python/index.html) in an AWS Glue job to call Amazon Comprehend APIs to get sentiment analysis on the review, convert the data into parquet, and [partition](https://docs.aws.amazon.com/athena/latest/ug/partitions.html) by sentiment. This will allow us to optimize analytics queries when viewing data by sentiment and returning just the values we need leveraging the columnar format of parquet.\n",
    "\n",
    "The example below is the API call required to pass text into the Comprehend API to detect sentiment and the result returned.\n",
    "\n",
    "[client.detect_sentiment](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/comprehend.html#Comprehend.Client.detect_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mixed': 3.170682248310186e-05,\n",
      " 'Negative': 8.217946015065536e-05,\n",
      " 'Neutral': 0.0002925922453869134,\n",
      " 'Positive': 0.9995934367179871}\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "\n",
    "client = boto3.client('comprehend', region_name=region)\n",
    "\n",
    "response = client.detect_sentiment(Text='This API call is awesome!!! So easy to get sentiment of text!', LanguageCode='en')\n",
    "pp.pprint(response['SentimentScore'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the code and other dependencies to S3 for AWS Glue\n",
    "In order to run your code in AWS Glue, we need to upload the code and dependencies directly to S3 and pass those locations while invoking the Glue job. We will write the ETL job using Jupyter Notebooks cell magic [%%writefile](https://ipython.readthedocs.io/en/stable/interactive/magics.html#cellmagic-writefile)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Sentiment of Yelp Review Data\n",
    "\n",
    "We will create a Pyspark job to add primary key and run a batch of reviews through [Amazon Comprehend](https://aws.amazon.com/comprehend/) to get sentiment analysis of the reviews. Replace `{region}` with the region this notebook is running in.\n",
    "\n",
    "The job will limit the number of rows it converts due to timeliness of the workshop, but this code could be modified to run the entire data set.\n",
    "\n",
    "The key points in this code is how easy it is to get access to the AWS Glue Data Catalog leveraging the [Glue libraries](https://github.com/awslabs/aws-glue-libs).\n",
    "\n",
    "* [`glueContext.create_dynamic_frame.from_catalog`](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-glue-context.html#aws-glue-api-crawler-pyspark-extensions-glue-context-create_dynamic_frame_from_catalog) - Read table metadata from the Glue Data Catalog using Glue libs to load tables into the job.\n",
    "* `yelpDF = yelp.toDF()` - Easy conversion from [Glue DynamicFrame](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame.html) to [Spark DataFrame](https://spark.apache.org/docs/latest/sql-programming-guide.html) and vice-versa `joinedsink= DynamicFrame.fromDF(joinedDF, glueContext, \"joined\")`.\n",
    "* Writing back S3 [`glueContext.write_dynamic_frame.from_options`](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-glue-context.html#aws-glue-api-crawler-pyspark-extensions-glue-context-write_dynamic_frame_from_catalog) with options:\n",
    "    * [Partition](https://docs.aws.amazon.com/athena/latest/ug/partitions.html) the data based on columns `connection_options = {\"path\": parquet_output_path, \"partitionKeys\": [\"sentiment\"]}`\n",
    "    * Convert data to a [columnar format](https://docs.aws.amazon.com/athena/latest/ug/columnar-storage.html) `format=\"parquet\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting yelp_etl.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile yelp_etl.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Row, Window, SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "args = getResolvedOptions(sys.argv, ['JOB_NAME', 'S3_OUTPUT_BUCKET', 'S3_OUTPUT_KEY_PREFIX', 'DATABASE_NAME', 'TABLE_NAME', 'REGION'])\n",
    "\n",
    "sc = SparkContext()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)\n",
    "job.init(args['JOB_NAME'], args)\n",
    "\n",
    "# Covert Glue DynamocFrame to Spark DataFrame\n",
    "yelp = glueContext.create_dynamic_frame.from_catalog(database=args['DATABASE_NAME'], table_name=args['TABLE_NAME'], transformation_ctx = \"datasource0\")\n",
    "yelpDF = yelp.toDF().select('rating', 'review')\n",
    "\n",
    "MIN_SENTENCE_LENGTH_IN_CHARS = 10 \n",
    "MAX_SENTENCE_LENGTH_IN_CHARS = 4500\n",
    "COMPREHEND_BATCH_SIZE = 5  ## This batch size results in groups no larger than 25 items\n",
    "NUMBER_OF_BATCHES = 10\n",
    "ROW_LIMIT = 1000 #Number of reviews we will process for this workshop\n",
    "\n",
    "## Each task handles 25*40 records, there should be 10 partitions overall to process 10000 records.\n",
    "ComprehendRow = Row(\"review\", \"rating\", \"sentiment\")\n",
    "\n",
    "def getBatchComprehend(input_list):\n",
    "    arr = []\n",
    "    bodies = [i[0] for i in input_list]\n",
    "    client = boto3.client('comprehend',region_name=args['REGION'])\n",
    "\n",
    "    def callApi(text_list):\n",
    "        response = client.batch_detect_sentiment(TextList = text_list, LanguageCode = 'en')\n",
    "        return response\n",
    "  \n",
    "    for i in range(NUMBER_OF_BATCHES):\n",
    "        text_list = bodies[COMPREHEND_BATCH_SIZE * i : COMPREHEND_BATCH_SIZE * (i+1)]\n",
    "        #response = client.batch_detect_sentiment(TextList = text_list, LanguageCode = 'en')\n",
    "        response = callApi(text_list)\n",
    "        for r in response['ResultList']:\n",
    "            idx = COMPREHEND_BATCH_SIZE * i + r['Index']\n",
    "            arr.append(ComprehendRow(input_list[idx][0], input_list[idx][1], r['Sentiment']))\n",
    "  \n",
    "    return arr\n",
    "\n",
    "# Grab a sample set of records with review size under Comprehend limits\n",
    "yelpDF = yelpDF \\\n",
    "  .withColumn('review_len', F.length('review')) \\\n",
    "  .filter(F.col('review_len') > MIN_SENTENCE_LENGTH_IN_CHARS) \\\n",
    "  .filter(F.col('review_len') < MAX_SENTENCE_LENGTH_IN_CHARS) \\\n",
    "  .limit(ROW_LIMIT)\n",
    "\n",
    "record_count = yelpDF.count()\n",
    "print('record count=' + str(record_count))\n",
    "\n",
    "yelpDF = yelpDF.repartition(record_count/(NUMBER_OF_BATCHES*COMPREHEND_BATCH_SIZE))\n",
    "\n",
    " ## Concatenate submission id and body tuples into arrays of similar size\n",
    "group_rdd = yelpDF.rdd.map(lambda l: (l.review.encode(\"utf-8\"), l.rating)).glom()\n",
    "  \n",
    "transformed = group_rdd \\\n",
    "  .map(lambda l: getBatchComprehend(l)) \\\n",
    "  .flatMap(lambda x: x) \\\n",
    "  .toDF()\n",
    "\n",
    "print(\"transformed count=\" + str(transformed.count()))\n",
    "      \n",
    "transformedsink = DynamicFrame.fromDF(transformed, glueContext, \"joined\")\n",
    "parquet_output_path = 's3://' + os.path.join(args['S3_OUTPUT_BUCKET'], args['S3_OUTPUT_KEY_PREFIX'])\n",
    "print(parquet_output_path)\n",
    "datasink5 = glueContext.write_dynamic_frame.from_options(frame = transformedsink, connection_type = \"s3\", connection_options = {\"path\": parquet_output_path, \"partitionKeys\": [\"sentiment\"]}, format=\"parquet\", transformation_ctx=\"datasink5\")\n",
    "                                                                                                                      \n",
    "job.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the Yelp ETL script to S3\n",
    "We will be uploading the `github_etl.py` script to S3 now so that Glue can use it to run the PySpark job. You can replace it with your own script if needed. If your code has multiple files, you need to zip those files and upload to S3 instead of uploading a single file like it's being done here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_location = sess.upload_data(path='yelp_etl.py', bucket=bucket, key_prefix='yelp/codes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output location of the data. The input data will be split, transformed, and \n",
    "# uploaded to output/train and output/validation\n",
    "s3_output_key_prefix = 'yelp/parquet/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling Glue APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll be creating Glue client via Boto so that we can invoke the `create_job` API of Glue. `create_job` API will create a job definition which can be used to execute your jobs in Glue. The job definition created here is mutable. While creating the job, we are also passing the code location as well as the dependencies location to Glue.\n",
    "\n",
    "`AllocatedCapacity` parameter controls the hardware resources that Glue will use to execute this job. It is measures in units of `DPU`. For more information on `DPU`, please see [here](https://docs.aws.amazon.com/glue/latest/dg/add-job.html).\n",
    "\n",
    "[glue.create_job](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/glue.html#Glue.Client.create_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp-etl-2021-05-25-14-30-19\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "import time\n",
    "\n",
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "job_name = 'yelp-etl-' + timestamp_prefix\n",
    "response = glue.create_job(\n",
    "    Name=job_name,\n",
    "    Description='PySpark job to extract Yelp review sentiment analysis',\n",
    "    Role=role, # you can pass your existing AWS Glue role here if you have used Glue before\n",
    "    ExecutionProperty={\n",
    "        'MaxConcurrentRuns': 1\n",
    "    },\n",
    "    Command={\n",
    "        'Name': 'glueetl',\n",
    "        'ScriptLocation': script_location\n",
    "    },\n",
    "    DefaultArguments={\n",
    "        '--job-language': 'python',\n",
    "        '--job-bookmark-option': 'job-bookmark-disable'\n",
    "    },\n",
    "    AllocatedCapacity=5,\n",
    "    Timeout=60,\n",
    ")\n",
    "glue_job_name = response['Name']\n",
    "print(glue_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aforementioned job will be executed now by calling `start_job_run` API. This API creates an immutable run/execution corresponding to the job definition created above. We will require the `job_run_id` for the particular job execution to check for status. We'll pass the data and model locations as part of the job execution parameters.\n",
    "\n",
    "[glue.start_job_run](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/glue.html#Glue.Client.start_job_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jr_f0f6e910a4bf543e97ce5fee5954a5027126c3731fc05034db2c24ed35318098\n"
     ]
    }
   ],
   "source": [
    "job_run_id = glue.start_job_run(JobName=job_name,\n",
    "                                       Arguments = {\n",
    "                                        '--S3_OUTPUT_BUCKET': bucket,\n",
    "                                        '--S3_OUTPUT_KEY_PREFIX': s3_output_key_prefix,\n",
    "                                        '--DATABASE_NAME': database_name,\n",
    "                                        '--TABLE_NAME': raw_table_name,\n",
    "                                        '--REGION': region\n",
    "                                       })['JobRunId']\n",
    "print(job_run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Glue Job status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will check for the job status to see if it has `SUCCEEDED`, `FAILED` or `STOPPED`. Once the job is succeeded, we have the transformed data into S3 in Parquet format which we will use to query with Athena and visualize with QuickSight. If the job fails, you can go to AWS Glue console, click on **Jobs** tab on the left, and from the page, click on this particular job and you will be able to find the CloudWatch logs (the link under **Logs**) link for these jobs which can help you to see what exactly went wrong in the job execution.\n",
    "\n",
    "[glue.get_job_run](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/glue.html#Glue.Client.get_job_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING\n",
      "RUNNING\n",
      "RUNNING\n",
      "SUCCEEDED\n",
      "SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "job_run_status = glue.get_job_run(JobName=job_name,RunId=job_run_id)['JobRun']['JobRunState']\n",
    "while job_run_status not in ('FAILED', 'SUCCEEDED', 'STOPPED'):\n",
    "    job_run_status = glue.get_job_run(JobName=job_name,RunId=job_run_id)['JobRun']['JobRunState']\n",
    "    print (job_run_status)\n",
    "    time.sleep(60)\n",
    "print(job_run_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a [Glue Crawler](https://docs.aws.amazon.com/glue/latest/dg/add-crawler.html) to Discover the transformed data\n",
    "\n",
    "You can use a crawler to populate the AWS Glue Data Catalog with tables. This is the primary method used by most AWS Glue users. You add a crawler within your Data Catalog to traverse your data stores. The output of the crawler consists of one or more metadata tables that are defined in your Data Catalog. Extract, transform, and load (ETL) jobs that you define in AWS Glue use these metadata tables as sources and targets.\n",
    "\n",
    "A crawler can crawl both file-based and table-based data stores. Crawlers can crawl the following data stores:\n",
    "\n",
    "* Amazon Simple Storage Service (Amazon S3)\n",
    "    * [Built-in Classifiers](https://docs.aws.amazon.com/glue/latest/dg/add-classifier.html#classifier-built-in)\n",
    "    * [Custom Classifiers](https://docs.aws.amazon.com/glue/latest/dg/custom-classifier.html)\n",
    "* Amazon Redshift\n",
    "* Amazon Relational Database Service (Amazon RDS)\n",
    "    * Amazon Aurora\n",
    "    * MariaDB\n",
    "    * Microsoft SQL Server\n",
    "    * MySQL\n",
    "    * Oracle\n",
    "    * PostgreSQL\n",
    "* Amazon DynamoDB\n",
    "* Publicly accessible databases [Blog](https://aws.amazon.com/blogs/big-data/how-to-access-and-analyze-on-premises-data-stores-using-aws-glue/)\n",
    "    * Aurora\n",
    "    * MariaDB\n",
    "    * SQL Server\n",
    "    * MySQL\n",
    "    * Oracle\n",
    "    * PostgreSQL\n",
    "\n",
    "[glue.create_crawler](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/glue.html#Glue.Client.create_crawler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "parq_crawler_name = 'YelpCuratedCrawler'\n",
    "parq_crawler_path = 's3://{0}/yelp/parquet/'.format(bucket)\n",
    "\n",
    "response = glue.create_crawler(\n",
    "    Name=parq_crawler_name,\n",
    "    Role=role,\n",
    "    DatabaseName=database_name,\n",
    "    Description='Crawler for the Parquet Yelp Reviews with Sentiment',\n",
    "    Targets={\n",
    "        'S3Targets': [\n",
    "            {\n",
    "                'Path': parq_crawler_path\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    SchemaChangePolicy={\n",
    "        'UpdateBehavior': 'UPDATE_IN_DATABASE',\n",
    "        'DeleteBehavior': 'DEPRECATE_IN_DATABASE'\n",
    "    },\n",
    "    TablePrefix='reviews_'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Glue Crawler\n",
    "\n",
    "You can use a crawler to populate the AWS Glue Data Catalog with tables. This is the primary method used by most AWS Glue users. You add a crawler within your Data Catalog to traverse your data stores. The output of the crawler consists of one or more metadata tables that are defined in your Data Catalog. Extract, transform, and load (ETL) jobs that you define in AWS Glue use these metadata tables as sources and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet Crawler: https://us-east-1.console.aws.amazon.com/glue/home?region=us-east-1#crawler:name=YelpCuratedCrawler\n"
     ]
    }
   ],
   "source": [
    "response = glue.start_crawler(\n",
    "    Name=parq_crawler_name\n",
    ")\n",
    "\n",
    "print (\"Parquet Crawler: https://{0}.console.aws.amazon.com/glue/home?region={0}#crawler:name={1}\".format(region, parq_crawler_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Glue crawler status\n",
    "\n",
    "We will now monitor the crawler status waiting for it to get back into the `READY` state meaning the crawler completed it's crawl. You can also look at the [CloudWatch logs](https://docs.aws.amazon.com/glue/latest/dg/console-crawlers.html#console-crawlers-details) for the crawler for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOPPING\n",
      "STOPPING\n",
      "STOPPING\n",
      "STOPPING\n",
      "STOPPING\n",
      "STOPPING\n",
      "STOPPING\n",
      "READY\n"
     ]
    }
   ],
   "source": [
    "crawler_status = glue.get_crawler(Name=parq_crawler_name)['Crawler']['State']\n",
    "while crawler_status not in ('READY'):\n",
    "    crawler_status = glue.get_crawler(Name=parq_crawler_name)['Crawler']['State']\n",
    "    print(crawler_status)\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View transformed results\n",
    "\n",
    "We will again us the PyAthena library to run queries against the newly created data set with sentiment result and in parquet format. In the interest of time, we will be using the [Bokeh](https://bokeh.pydata.org/en/latest/) within the notebook to visualize the results instead of [Amazon QuickSight](https://aws.amazon.com/quicksight/). QuickSight is able to use the same Athena queries to visualize the results as well as numerous [built-in connectors](https://docs.aws.amazon.com/quicksight/latest/user/supported-data-sources.html) to many datasources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Meet up with some friends Sat night to have so...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>these guys are great! not only did the tech se...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>I've been going to this place for 29 years. Th...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Super duper friendly staff!!! The people playi...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5 stars, this place is as good as it gets! I d...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Very nice place to eat! Friendly device, great...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>I was pleasantly surprised by the amazing food...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Timing is what it's all about people!!  \\nThe ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>The  food is good. I took it to go. When I got...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>Have the chicken avocado burrito. It was great.</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rating                                             review sentiment\n",
       "0      2  Meet up with some friends Sat night to have so...  POSITIVE\n",
       "1      5  these guys are great! not only did the tech se...  POSITIVE\n",
       "2      5  I've been going to this place for 29 years. Th...  POSITIVE\n",
       "3      4  Super duper friendly staff!!! The people playi...  POSITIVE\n",
       "4      5  5 stars, this place is as good as it gets! I d...  POSITIVE\n",
       "5      4  Very nice place to eat! Friendly device, great...  POSITIVE\n",
       "6      4  I was pleasantly surprised by the amazing food...  POSITIVE\n",
       "7      3  Timing is what it's all about people!!  \\nThe ...  POSITIVE\n",
       "8      4  The  food is good. I took it to go. When I got...  POSITIVE\n",
       "9      4    Have the chicken avocado burrito. It was great.  POSITIVE"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('select rating, review, sentiment from yelp.reviews_parquet')\n",
    "\n",
    "df = as_pandas(cursor)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group  the data in the DataFrame by Sentiment\n",
    "\n",
    "Using Pandas DataFrame functionality we will do the groupby locally. Alternatively we could have used the built-in [SQL and Aggregate functions](https://docs.aws.amazon.com/athena/latest/ug/functions-operators-reference-section.html) in Athena to achieve the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">rating</th>\n",
       "      <th colspan=\"4\" halign=\"left\">review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MIXED</th>\n",
       "      <td>220</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>A neighbor recommended Franks all about time a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEGATIVE</th>\n",
       "      <td>333</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>211</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>Back in the day before there were $14 gourmet ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEUTRAL</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>I would try to help a real non-profit that is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POSITIVE</th>\n",
       "      <td>435</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>176</td>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "      <td>This place is a little fat Mexican girl's drea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rating                 review         \\\n",
       "           count unique top freq  count unique   \n",
       "sentiment                                        \n",
       "MIXED        220      5   3   81    220    220   \n",
       "NEGATIVE     333      5   1  211    333    333   \n",
       "NEUTRAL       12      3   1    6     12     12   \n",
       "POSITIVE     435      5   5  176    435    435   \n",
       "\n",
       "                                                                   \n",
       "                                                         top freq  \n",
       "sentiment                                                          \n",
       "MIXED      A neighbor recommended Franks all about time a...    1  \n",
       "NEGATIVE   Back in the day before there were $14 gourmet ...    1  \n",
       "NEUTRAL    I would try to help a real non-profit that is ...    1  \n",
       "POSITIVE   This place is a little fat Mexican girl's drea...    1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = df.groupby(('sentiment'))\n",
    "group.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results\n",
    "\n",
    "The Bokeh framework has a number of built-in visualizations. \n",
    "#### Visualize by Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"43eec1d3-38a0-46dd-a857-9df39dbead29\" data-root-id=\"1004\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"2d86edb6-25b1-4d70-8d08-eb947dffaee3\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1013\"}],\"center\":[{\"id\":\"1015\"},{\"id\":\"1019\"}],\"left\":[{\"id\":\"1016\"}],\"plot_height\":350,\"renderers\":[{\"id\":\"1037\"}],\"title\":{\"id\":\"1040\"},\"toolbar\":{\"id\":\"1027\"},\"x_range\":{\"id\":\"1005\"},\"x_scale\":{\"id\":\"1009\"},\"y_range\":{\"id\":\"1007\"},\"y_scale\":{\"id\":\"1011\"}},\"id\":\"1004\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"axis_label\":\"Sentiment\",\"formatter\":{\"id\":\"1043\"},\"ticker\":{\"id\":\"1014\"}},\"id\":\"1013\",\"type\":\"CategoricalAxis\"},{\"attributes\":{},\"id\":\"1043\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1026\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"1017\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1046\",\"type\":\"Selection\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"sentiment\",\"transform\":{\"id\":\"1003\"}},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"white\"},\"top\":{\"field\":\"rating_count\"},\"width\":{\"value\":1},\"x\":{\"field\":\"sentiment\"}},\"id\":\"1036\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"1047\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"CategoricalTicker\"},{\"attributes\":{\"axis_label\":\"Count\",\"formatter\":{\"id\":\"1041\"},\"ticker\":{\"id\":\"1017\"}},\"id\":\"1016\",\"type\":\"LinearAxis\"},{\"attributes\":{\"axis\":{\"id\":\"1013\"},\"grid_line_color\":null,\"ticker\":null},\"id\":\"1015\",\"type\":\"Grid\"},{\"attributes\":{\"source\":{\"id\":\"1002\"}},\"id\":\"1038\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1020\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"CategoricalScale\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"start\":0},\"id\":\"1007\",\"type\":\"DataRange1d\"},{\"attributes\":{\"overlay\":{\"id\":\"1026\"}},\"id\":\"1022\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"axis\":{\"id\":\"1016\"},\"dimension\":1,\"ticker\":null},\"id\":\"1019\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"SaveTool\"},{\"attributes\":{\"data\":{\"rating_count\":[220,333,12,435],\"rating_freq\":[81,211,6,176],\"rating_top\":[\"3\",\"1\",\"1\",\"5\"],\"rating_unique\":[5,5,3,5],\"review_count\":[220,333,12,435],\"review_freq\":[1,1,1,1],\"review_top\":[\"A neighbor recommended Franks all about time and so I took him a wall clock which he fixed well and it worked fine.  I did take him an unreasonable amount of time to do the work though.\\nIn October I brought him another clock.  This one had only hands that flopped around although the clock ran well.  About 3 weeks later, I received a call saying it was gonna' cost this much and he'd have it ready the week after thanksgiving.  Bear in mind that he had from October to late November to inspect it, repair it, etc.  Anyway, two and a half weeks after Thanksgiving I called to find out when I could pick up the clock not having heard otherwise from him.  I was then told that although the clock hands probably needed replacement, he had gone into the clock works and now it doesn't work.  Would need a complete overhaul  to the tune of 400$ and would take him 10 MONTHS to get around to starting repair.  \\nIf you have a lot of time to wait and a lot of money to spend this is the place to go.\",\"Back in the day before there were $14 gourmet burgers complete with locally sourced pickles there was the type of burger joint embodied by a place like Lenny's.  This is an old fashioned, calorie busting, get a malt type of place.\",\"I would try to help a real non-profit that is out to help the community that have full time jobs and not just people that can wait all day to get services.\",\"This place is a little fat Mexican girl's dream come true! They have yummy ribeye tacos, nachos, fresas con cream, paletas, pan dulce, thirst quenching agua frescas, even their darn soups are the bomb! Whether I'm stressed, bored, or need a treat...this place and its huge selection always deliver.\\nOnly con, place gets packed so you have to run to get an open table and clean it too; since staff is uber busy. :-/\\n\\nDress: come as you are!\"],\"review_unique\":[220,333,12,435],\"sentiment\":[\"MIXED\",\"NEGATIVE\",\"NEUTRAL\",\"POSITIVE\"]},\"selected\":{\"id\":\"1046\"},\"selection_policy\":{\"id\":\"1047\"}},\"id\":\"1002\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"ResetTool\"},{\"attributes\":{\"factors\":[\"MIXED\",\"NEGATIVE\",\"NEUTRAL\",\"POSITIVE\"]},\"id\":\"1005\",\"type\":\"FactorRange\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"HelpTool\"},{\"attributes\":{\"factors\":[\"MIXED\",\"NEGATIVE\",\"NEUTRAL\",\"POSITIVE\"],\"palette\":[\"#2b83ba\",\"#abdda4\",\"#ffffbf\",\"#fdae61\",\"#d7191c\"]},\"id\":\"1003\",\"type\":\"CategoricalColorMapper\"},{\"attributes\":{},\"id\":\"1041\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1011\",\"type\":\"LinearScale\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1020\"},{\"id\":\"1021\"},{\"id\":\"1022\"},{\"id\":\"1023\"},{\"id\":\"1024\"},{\"id\":\"1025\"}]},\"id\":\"1027\",\"type\":\"Toolbar\"},{\"attributes\":{\"text\":\"\"},\"id\":\"1040\",\"type\":\"Title\"},{\"attributes\":{\"fill_color\":{\"field\":\"sentiment\",\"transform\":{\"id\":\"1003\"}},\"line_color\":{\"value\":\"white\"},\"top\":{\"field\":\"rating_count\"},\"width\":{\"value\":1},\"x\":{\"field\":\"sentiment\"}},\"id\":\"1035\",\"type\":\"VBar\"},{\"attributes\":{\"data_source\":{\"id\":\"1002\"},\"glyph\":{\"id\":\"1035\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1036\"},\"selection_glyph\":null,\"view\":{\"id\":\"1038\"}},\"id\":\"1037\",\"type\":\"GlyphRenderer\"}],\"root_ids\":[\"1004\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "  var render_items = [{\"docid\":\"2d86edb6-25b1-4d70-8d08-eb947dffaee3\",\"root_ids\":[\"1004\"],\"roots\":{\"1004\":\"43eec1d3-38a0-46dd-a857-9df39dbead29\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1004"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.palettes import Spectral5\n",
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.models import ColumnDataSource\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "source = ColumnDataSource(group)\n",
    "\",\".join(source.column_names)\n",
    "\n",
    "sent_cmap = factor_cmap('sentiment', palette=Spectral5, factors=sorted(df.sentiment.unique()))\n",
    "\n",
    "p = figure(plot_height=350, x_range=group)\n",
    "p.vbar(x='sentiment', top='rating_count', width=1, line_color=\"white\", \n",
    "       fill_color=sent_cmap, source=source)\n",
    "\n",
    "p.xgrid.grid_line_color = None\n",
    "p.xaxis.axis_label = \"Sentiment\"\n",
    "p.yaxis.axis_label = \"Count\"\n",
    "p.y_range.start = 0\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize by Rating\n",
    "\n",
    "We will now compare what the Comprehend API came up with compared to the user rating in the data set. We are changing the group by in the dataframe to change the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">review</th>\n",
       "      <th colspan=\"4\" halign=\"left\">sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>I called Central Towing last night because I h...</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>10pm on a Friday night.  Wanted a hassle free ...</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>3</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>Alright store and what you would normally expe...</td>\n",
       "      <td>1</td>\n",
       "      <td>191</td>\n",
       "      <td>4</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>Food was delicious, has a store too.</td>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "      <td>3</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>I stopped at this waffle house it was really g...</td>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>4</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review                                                                 \\\n",
       "        count unique                                                top freq   \n",
       "rating                                                                         \n",
       "1         256    256  I called Central Towing last night because I h...    1   \n",
       "2         178    178  10pm on a Friday night.  Wanted a hassle free ...    1   \n",
       "3         191    191  Alright store and what you would normally expe...    1   \n",
       "4         190    190               Food was delicious, has a store too.    1   \n",
       "5         185    185  I stopped at this waffle house it was really g...    1   \n",
       "\n",
       "       sentiment                        \n",
       "           count unique       top freq  \n",
       "rating                                  \n",
       "1            256      4  NEGATIVE  211  \n",
       "2            178      3  NEGATIVE   97  \n",
       "3            191      4  POSITIVE   87  \n",
       "4            190      3  POSITIVE  146  \n",
       "5            185      4  POSITIVE  176  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = df.groupby(('rating'))\n",
    "group.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize by User Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"52cc349b-2390-4ff9-991c-cab7c01b8258\" data-root-id=\"1095\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"814e19a0-9b37-44a3-9f87-1a5c916e583c\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1104\"}],\"center\":[{\"id\":\"1106\"},{\"id\":\"1110\"}],\"left\":[{\"id\":\"1107\"}],\"plot_height\":350,\"renderers\":[{\"id\":\"1128\"}],\"title\":{\"id\":\"1140\"},\"toolbar\":{\"id\":\"1118\"},\"x_range\":{\"id\":\"1096\"},\"x_scale\":{\"id\":\"1100\"},\"y_range\":{\"id\":\"1098\"},\"y_scale\":{\"id\":\"1102\"}},\"id\":\"1095\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"data_source\":{\"id\":\"1093\"},\"glyph\":{\"id\":\"1126\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1127\"},\"selection_glyph\":null,\"view\":{\"id\":\"1129\"}},\"id\":\"1128\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1143\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{},\"id\":\"1105\",\"type\":\"CategoricalTicker\"},{\"attributes\":{\"text\":\"\"},\"id\":\"1140\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1102\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1141\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"axis_label\":\"Count\",\"formatter\":{\"id\":\"1141\"},\"ticker\":{\"id\":\"1108\"}},\"id\":\"1107\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1146\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1108\",\"type\":\"BasicTicker\"},{\"attributes\":{\"source\":{\"id\":\"1093\"}},\"id\":\"1129\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1111\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1147\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"fill_color\":{\"field\":\"rating\",\"transform\":{\"id\":\"1094\"}},\"line_color\":{\"value\":\"white\"},\"top\":{\"field\":\"review_count\"},\"width\":{\"value\":1},\"x\":{\"field\":\"rating\"}},\"id\":\"1126\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"1114\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1115\",\"type\":\"ResetTool\"},{\"attributes\":{\"overlay\":{\"id\":\"1117\"}},\"id\":\"1113\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1100\",\"type\":\"CategoricalScale\"},{\"attributes\":{\"data\":{\"rating\":[\"1\",\"2\",\"3\",\"4\",\"5\"],\"review_count\":[256,178,191,190,185],\"review_freq\":[1,1,1,1,1],\"review_top\":[\"I called Central Towing last night because I had accidentally locked my keys inside my car. They said it was going to be about a 25 minute wait. After an hour I called several times... no answer. They didn't show up until an hour and a half later!\",\"10pm on a Friday night.  Wanted a hassle free french dip sandwich.  Tried Subway substitute steak sandwich.  Horrible.  How can they call it meat let alone steak?\",\"Alright store and what you would normally expect. Starbucks inside and moderately priced goods.\",\"Food was delicious, has a store too.\",\"I stopped at this waffle house it was really good, affordable prices and the waffle was soooo good. I was surprised even the people were ok dint expect this since I was in Arizona, maybe everyone is just happy since the food is so good. Its a small place seems everyone is eating next to each other but you forget it once you get your order. Wish we had them in the LA area as we lack breakfast places that are actualy good.\"],\"review_unique\":[256,178,191,190,185],\"sentiment_count\":[256,178,191,190,185],\"sentiment_freq\":[211,97,87,146,176],\"sentiment_top\":[\"NEGATIVE\",\"NEGATIVE\",\"POSITIVE\",\"POSITIVE\",\"POSITIVE\"],\"sentiment_unique\":[4,3,4,3,4]},\"selected\":{\"id\":\"1146\"},\"selection_policy\":{\"id\":\"1147\"}},\"id\":\"1093\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"axis\":{\"id\":\"1104\"},\"grid_line_color\":null,\"ticker\":null},\"id\":\"1106\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1112\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"factors\":[\"1\",\"2\",\"3\",\"4\",\"5\"],\"palette\":[\"#2b83ba\",\"#abdda4\",\"#ffffbf\",\"#fdae61\",\"#d7191c\"]},\"id\":\"1094\",\"type\":\"CategoricalColorMapper\"},{\"attributes\":{\"start\":0},\"id\":\"1098\",\"type\":\"DataRange1d\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1111\"},{\"id\":\"1112\"},{\"id\":\"1113\"},{\"id\":\"1114\"},{\"id\":\"1115\"},{\"id\":\"1116\"}]},\"id\":\"1118\",\"type\":\"Toolbar\"},{\"attributes\":{\"axis\":{\"id\":\"1107\"},\"dimension\":1,\"ticker\":null},\"id\":\"1110\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1116\",\"type\":\"HelpTool\"},{\"attributes\":{\"factors\":[\"1\",\"2\",\"3\",\"4\",\"5\"]},\"id\":\"1096\",\"type\":\"FactorRange\"},{\"attributes\":{\"axis_label\":\"Rating\",\"formatter\":{\"id\":\"1143\"},\"ticker\":{\"id\":\"1105\"}},\"id\":\"1104\",\"type\":\"CategoricalAxis\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1117\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"rating\",\"transform\":{\"id\":\"1094\"}},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"white\"},\"top\":{\"field\":\"review_count\"},\"width\":{\"value\":1},\"x\":{\"field\":\"rating\"}},\"id\":\"1127\",\"type\":\"VBar\"}],\"root_ids\":[\"1095\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "  var render_items = [{\"docid\":\"814e19a0-9b37-44a3-9f87-1a5c916e583c\",\"root_ids\":[\"1095\"],\"roots\":{\"1095\":\"52cc349b-2390-4ff9-991c-cab7c01b8258\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1095"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "source = ColumnDataSource(group)\n",
    "\",\".join(source.column_names)\n",
    "\n",
    "rating_cmap = factor_cmap('rating', palette=Spectral5, factors=sorted(df.rating.unique()))\n",
    "\n",
    "p = figure(plot_height=350, x_range=group)\n",
    "p.vbar(x='rating', top='review_count', width=1, line_color=\"white\", \n",
    "       fill_color=rating_cmap, source=source)\n",
    "\n",
    "p.xgrid.grid_line_color = None\n",
    "p.xaxis.axis_label = \"Rating\"\n",
    "p.yaxis.axis_label = \"Count\"\n",
    "p.y_range.start = 0\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Amazon QuickSight](https://aws.amazon.com/quicksight/) visualization\n",
    "\n",
    "We can also visualize the data in [Amazon QuickSight](https://aws.amazon.com/quicksight/). You can follow allow with the [Getting Started](https://docs.aws.amazon.com/quicksight/latest/user/getting-started.html) guide for QuickSight to setup your account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://us-east-1.quicksight.aws.amazon.com/sn/start?#\n"
     ]
    }
   ],
   "source": [
    "print('https://{0}.quicksight.aws.amazon.com/sn/start?#'.format(region))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manage Data sets\n",
    "\n",
    "Once your account it created you will start by clicking the `Manage Data` button to create a new dataset that uses Amazon Athena to query the data. Click the `New data set` button and select the `Athena` data source, name the data source, and choose the `yelp` Glue database and `reviews_parquet` table. Finish creation by clicking the `Create data source` button. QuickSight supports a number of [Data Connectors](https://docs.aws.amazon.com/quicksight/latest/user/supported-data-sources.html). \n",
    "\n",
    "![QS Manage Data](../../docs/assets/images/qs_manage_data.png)\n",
    "\n",
    "***\n",
    "\n",
    "#### [Create New Data Set from S3](https://docs.aws.amazon.com/quicksight/latest/user/create-a-data-set-s3.html)\n",
    "\n",
    "To create a data set using one or more text files (.csv, .tsv, .clf, or .elf) from Amazon S3, create a manifest that Amazon QuickSight can use to identify the files that you want to use, and also the upload settings needed to import them. When you create a data set using Amazon S3, the file data is automatically imported into [SPICE](https://docs.aws.amazon.com/quicksight/latest/user/welcome.html#spice).\n",
    "\n",
    "![QS Manage Data](../../docs/assets/images/qs_new_dataset.png)\n",
    "\n",
    "#### [Creating a Data Set Using Amazon Athena Data](https://docs.aws.amazon.com/quicksight/latest/user/create-a-data-set-athena.html)\n",
    "\n",
    "You can connect to Amazon Athena data sources and use Athena data to create Amazon QuickSight data sets.\n",
    "\n",
    "Before you try to read files from Amazon S3 buckets, make sure that you grant Amazon QuickSight access to them. For more information, see [Managing Amazon QuickSight Permissions to AWS Resources](https://docs.aws.amazon.com/quicksight/latest/user/managing-permissions.html).\n",
    "\n",
    "In the `Data source name` textbox enter the name `yelp_reviews` and click `Create data source`.\n",
    "\n",
    "![QS Manage Data](../../docs/assets/images/qs_athena_ds.png)\n",
    "\n",
    "#### Chose the Glue table for Athena\n",
    "\n",
    "Next, you will be selecting the `yelp` database we created in the Glue Data Catalog and the `reviews_parquet` table.\n",
    "\n",
    "![QS Manage Data](../../docs/assets/images/qs_choose_table.png)\n",
    "\n",
    "#### Edit the data set\n",
    "\n",
    "![QS Edit Data Set](../../docs/assets/images/qs_data_edit.png)\n",
    "\n",
    "#### Visualize!\n",
    "\n",
    "![QS Edit Data Set](../../docs/assets/images/qs_visual.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "We will finish this workshop by removing the resources created in this notebook. Ensure each cell completes successfully to verify all resources have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = glue.delete_crawler(Name=parq_crawler_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = glue.delete_job(JobName=glue_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = glue.delete_database(\n",
    "    CatalogId = account_id,\n",
    "    Name = database_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workshop.delete_bucket_completely(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
